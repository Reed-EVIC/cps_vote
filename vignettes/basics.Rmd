---
title: "`cpsvote` Basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  \usepackage[utf8]{inputenc}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  messages = FALSE, warnings = FALSE
)
library(knitr)
library(kableExtra)

```

`cpsvote` helps you work with data from the Current Population Survey's (CPS) Voting and Registration Supplement (VRS), published by the U.S. Census Bureau and Bureau of Labor Statistics. This high-quality survey has been conducted after every federal election (in November of even years) since the 1960s. The raw data, archived by the [National Bureau of Economic Research](http://data.nber.org/data/current-population-survey-data.html), is spread across several fixed-width files with different question locations and formats. This package consolidates common questions and provides the data in a structure that is much easier to work with and interpret, since some of the basic factor recoding has already been done. We have provided access to VRS data from 1994 to 2018, and anticipate updating the package when 2020 data becomes available.

## Installing the Package

```{r eval = FALSE}
install.packages('cpsvote')
```

You can also install the development version from our [GitHub repository](https://github.com/Reed-EVIC/cpsvote).

```{r eval = FALSE}
remotes::install_github("Reed-EVIC/cpsvote")
```

## Basic Use

We have written several functions to transform the VRS from its original format into a more workable structure. The easiest way to access the data is with the `cps_load_basic()` command:

```{r eval = FALSE}
cps <- cps_load_basic(years = c(2006, 2008))
```

This will load the prepared VRS data (here, from 2006 and 2008) into your environment as a tibble called `cps`. The first time you try to load a given year of data, the raw data file will be downloaded to your computer (defaulting to the relative path "./cps_data"). This can take some time depending on your internet speeds. In future instances, R will just read from the data files that have already been downloaded (defaulting to the same "cps_data" folder), as long as you correctly specify where these are stored.

We recommend using a single R project for your CPS analysis where these files can be stored (this will work with the default options), or storing one set of CPS files in a steady location and specifying this absolute file path each time you load in the data. If you specify a location that does not have the correct files, these functions will attempt to re-download the data from NBER, which can take up noticeable time and storage space.

We have also included a 10,000 row sample of the full VRS data, which comes with the package as `cps_sample_10k`. This is particularly useful for planning out a given analysis before you download the full data sets.

```{r}
data("cps_sample_10k")

cps_sample_10k %>%
  select(1:3, VRS_VOTE:VRS_REG, VRS_VOTEMETHOD_CON, turnout_weight) %>%
  sample_n(10)
```

The CPS has survey weights that are necessary to calculate accurate estimates about the US population. Two R packages that work with survey weighting are [`survey`](http://r-survey.r-forge.r-project.org/survey/) and [`srvyr`](https://github.com/gergness/srvyr) (a tidyverse-compatible wrapper for `survey`). You can see more examples and details on weighting in the BLANK vignette, but here is one example of using `srvyr` to calculate state-level voter turnout among eligible voters in 2018.

```{r message=F, warning = F}
library(cpsvote)
library(dplyr)
library(srvyr)

cps18_weighted <- cps_load_basic(years = 2018, datadir = here::here('cps_data')) %>%
  as_survey_design(weights = turnout_weight)

turnout18 <- cps18_weighted %>%
  group_by(STATE) %>%
  summarize(turnout = survey_mean(hurachen_turnout == "YES", na.rm = TRUE))

head(turnout18, 10)
```

These estimated line up with Dr. Michael McDonald's [estimates of turnout](http://www.electproject.org/2018g) among eligible voters in the November 2018 General Election. For an explanation of why these numbers line up so closely (and the multiple variables for turnout and weight), see the BLANK vignette.

## Advanced Use

In addition to the basic function listed above, you can customize several steps in the process of reading in the VRS data. If you've worked with the CPS before, you may already have some code to read in analyze this survey data. We still hope that this package can help you organize your workflow or ease some of the more tedious steps necessary to work with the CPS.

Be sure to refer to the CPS documentation files when working with alternative versions of the VRS data. We have included the function `cps_download_docs()` to provide the documentation versions that match this data. These are all in PDF format (and several are not text-based), so they are not easy to search through.

`cps_load_basic()` is a wrapper for several constituent steps that have their own parameters and assumptions. We've detailed the changes made to get from the raw data file to the cleaned file in the BLANK vignette.

```{r eval=F}
cps_read(years = seq(1994, 2018, 2),
         dir = "cps_data",
         cols = cpsvote::cps_cols,
         names_col = "new_name",
         join_dfs = TRUE) %>%
    cps_label(factors = cpsvote::cps_factors,
              names_col = "new_name",
              na_vals = c("-1", "BLANK", "NOT IN UNIVERSE"),
              expand_year = TRUE,
              rescale_weight = TRUE) %>%
    cps_refactor(move_levels = TRUE) %>%
    cps_recode_vote(vote_col = "VRS_VOTE",
                    items = c("DON'T KNOW", "REFUSED", "NO RESPONSE")) %>%
    cps_reweight_turnout()
```

- `cps_read()` is the function that actually loads in the original, (mostly) numeric data from files defined by the arguments `years` and `dir`. Since the raw data is in fixed-width files, you have to define the range of characters that are read. You can see the default set of columns in the included data set `cps_cols`, or supply `cols` with your own specifications of columns (for details on adding other columns, see the BLANK vignette). The `names_col` argument details which variable in `cols` will become the column names for the output; we have provided the original CPS names as `cps_name`, but recommend using `new_name` as it is more informative and accounts for questions changing names ("PES5", "PES6", etc.) across multiple years. `join_dfs` lets you join multiple years into one `tibble`, and should only be used if you're sure that a column name (like "PES5") refers to the same question across all years you read in.
- `cps_label()` replaces the numeric entries from the raw data with appropriate factor levels (as given by the data documentation; see `cps_download_docs()`). We have taken the factor levels as written from the PDFs, including capitalization, typos, and differences across years. This is provided in the `cps_factors` dataset, but you can supply the `factors` argument with your own coding (for details on changing factor levels or adding them for a new column, see the BLANK vignette). The `names_col` argument defines which column of `factors` contains the column names that match the incoming data set to be labelled. Further: `na_vals` defines which factor levels should be marked as `NA`, `expand_year` turns the two-digit years in some files into four-digit years (e.g. "94" becomes "1994"), and `rescale_weight` divides the given weight by 10,000 (as noted by the data documentation) to ensure accurate population sums.
- `cps_refactor` deals with all of the typos, capitalization, and shifting questions across years. We have attempted here to consolidate factor levels and variables in a way that makes sense. For example, one common method of assessing vote mode (in-person on Election Day, early in-person, or by mail) has been split between two separate questions from 2004 onwards, and this function consolidates those two questions (and the one question of previous surveys) into one `VRS_VOTEMETHOD_CON` variable. Note that this function will only work with certain column names in the data; see BLANK vignette for more details.

## Examples, Background Reading, and Sources

- List of Vignettes
- Achen & Hur Paper
- McDonald Paper
- NBER repository
